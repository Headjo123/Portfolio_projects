{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOmFsr26q4EIpTsn9UuUAu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping \"List of Largest Companies in the United States based on Revenue\" data from Wikipedia\n",
        "\n",
        "This is a portfolio project on webscraping. Variable names are as follows:\n",
        "* url =  Scraped Webpage URL\n",
        "* page = Server data\n",
        "* soup = HTML version of webpage\n",
        "* table = The table tag with class = 'wikitable sortable'\n",
        "* us_headers = Column headers of the table in \"table\" above\n",
        "* us_comp_headers = Text version of the Header names in \"us_headers\" above\n",
        "* us_comp_rev_data = The entire datafame\n",
        "* us_comp_column_data = Each row in the table in \"table\" above\n",
        "* row_data = Individual entries in each column of a row in \"us_comp_column_data\" above\n",
        "* individual_row_data = Textual and stripped version of \"row_data\"\n",
        "* length = Dataframe length\n",
        "\n",
        "Link to webpage: [List of Largest Companies in the United States based on Revenue](https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z-mk9JvTzvGe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KeUv7s4E1jjR"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify webpage url\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue'"
      ],
      "metadata": {
        "id": "jpa-pDJ-7z99"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send a request to the webpage\n",
        "page = requests.get(url)\n",
        "\n",
        "# Extract HTML version of webpage\n",
        "soup = BeautifulSoup(page.text, 'html')"
      ],
      "metadata": {
        "id": "fd1copOSI6AT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup)"
      ],
      "metadata": {
        "id": "ofzE0SONJucb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pulling the table using the find_all function and its index in the list.\n",
        "soup.find_all('table')[1]"
      ],
      "metadata": {
        "id": "TzlPJMQbLZVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pulling the data using find and the table's class (Either this or the code before this will suffice)\n",
        "table = soup.find('table', class_ = 'wikitable sortable')"
      ],
      "metadata": {
        "id": "KSnutorTK1vC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracts the column headers from the table\n",
        "us_headers = table.find_all('th')\n",
        "\n",
        "us_comp_headers = [titles.text.strip() for titles in us_headers]\n",
        "us_comp_headers"
      ],
      "metadata": {
        "id": "vNyMnuguqk9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert column names into a pandas dataframe\n",
        "us_comp_rev_data = pd.DataFrame(columns = us_comp_headers)\n",
        "us_comp_rev_data"
      ],
      "metadata": {
        "id": "N3CaN0yhsjgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all the rows of data\n",
        "us_comp_column_data = table.find_all('tr')\n",
        "\n",
        "# Loop through the list of rows, extract the individual data and add it to the dataframe\n",
        "for row in us_comp_column_data[1:]:\n",
        "  row_data = row.find_all('td')\n",
        "  individual_row_data = [data.text.strip() for data in row_data]\n",
        "  length = len(us_comp_rev_data)\n",
        "  us_comp_rev_data.loc[length] = individual_row_data"
      ],
      "metadata": {
        "id": "k886lqdCvqFq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display dataframe\n",
        "us_comp_rev_data"
      ],
      "metadata": {
        "id": "jQ3gTK9ey0nB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}